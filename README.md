## Welcome to STATS 315 / DATA SCI 315

This is an introductory deep learning course using the Python programming language and the TensorFlow deep learning library.

- **Textbook**: We will not follow any one textbook too closely. Here are a few references we will use:
  - _Dive into Deep Learning_ by Zhang, Lipton, Li and Smola. An advanced text from research scientists at Amazon. It weaves together math, figures, and code in an interactive online resource available [here](https://d2l.ai/). Code examples are provided in three frameworks: MXNet, PyTorch and TensorFlow. 
  - _Deep Learning with Python (2nd edition)_ by Chollet. A solid hands-on guide oriented towards programmers from the creator of the Keras deep learning library. Ebook and print versions are available from [Manning Publications](https://www.manning.com/books/deep-learning-with-python-second-edition)  
  - _Deep Learning_ by Goodfellow, Bengio and Courville. Written by three top deep learning researchers, this comprehensive book is required reading if you want to pursue your study of deep learning at a more advanced level. Print version is available from [MIT Press](https://mitpress.mit.edu/books/deep-learning) and an online version is [here](https://www.deeplearningbook.org/).
  - _Understanding Deep Learning_ by Simon J.D. Prince. It promises to be a more up-to-date version of _Deep Learning_ by Goodfellow et al. and its spiritual successor. Print version is available from [MIT Press](https://mitpress.mit.edu/9780262048644/understanding-deep-learning/) and an online version is [here](https://udlbook.github.io/udlbook/).
  
- **Undergraduate Courses on Deep Learning**: Many universities now offer an introductory deep learning course, e.g., [Berkeley](https://inst.eecs.berkeley.edu/~cs182), [CMU](https://deeplearning.cs.cmu.edu/), [MIT](http://introtodeeplearning.com/), [Stanford](https://cs230.stanford.edu/)
- **Canvas**: You should access the [Canvas class page](https://umich.instructure.com/courses/657959) for this course frequently. It will let you access important announcements and track course deliverables. (requires UM login)
- **Slack**: The course slack workspace is at [um-wn24-stats315.slack.com](https://um-wn24-stats315.slack.com) (requires UM login)
- **Days and Times**: Tuesdays and Thursdays, 1-2:30
- **Location**: [170 WEISER](https://maps.studentlife.umich.edu/building/weiser-hall) (links for virtual lectures, if any, will be saved in the syllabus page on canvas)

## Instructor Information

**Name**: Ambuj Tewari  
**Office Hours**: by appointment (send me an email or slack DM)  
**Email**: [tewaria@umich.edu](mailto:tewaria@umich.edu)

## GSI Information

**Name**: Sahana Rayan (Lab 002 Thu 8:30-10:00 in 335 WH)  
**Email**: [srayan@umich.edu](mailto:srayan@umich.edu)

**Name**: Jacob (Jake) Trauger (Lab 003 Thu 2:30-4:00 in 2234 USB)   
**Email**: [jtrauger@umich.edu](jtrauger@umich.edu)

**Name**: Abhiti Mishra (Lab 004 Thu 4:00-5:30 in 1084 EH)  
**Email**: [abhiti@umich.edu](mailto:abhiti@umich.edu)

**Lab webpage** (also has GSI office hours info): [link](https://docs.google.com/document/d/1hFF-2ulqIBcvFur12F52eCDM-UJGyHgvVszrUTLJL-s/edit?usp=sharing)

## Grading

- Canvas quizzes (20%): Timed, multiple choice, open book. Will drop two lowest scores
- Homeworks (30%): Assigned roughly every other week. Will drop one lowest score
- Midterm Exam (20%): In class, timed, multiple choice, open book
- Final Exam (30%): In class, timed, multiple choice, open book

## Academic Integrity

The University of Michigan community functions best when its members treat one another with honesty, fairness, respect, and trust. The college promotes the assumption of personal responsibility and integrity, and prohibits all forms of academic dishonesty and misconduct. All cases of academic misconduct will be referred to the LSA Office of the Assistant Dean for Undergraduate Education. Being found responsible for academic misconduct will usually result in a grade sanction, in addition to any sanction from the college. For more information, including examples of behaviors that are considered academic misconduct and potential sanctions, please see [https://lsa.umich.edu/lsa/academics/academic-integrity.html](https://lsa.umich.edu/lsa/academics/academic-integrity.html)

## Accommodation for Students with Disabilities

If you think you need accommodation for a disability, please let me know at your earliest convenience. Some aspects of this course, the assignments, the in-class activities, and the way the course is usually taught may be modified to facilitate your participation and progress. As soon as you make me aware of your needs, we can work with the Office of Services for Students with Disabilities (SSD) to help us determine appropriate academic accommodations. SSD (734-763-3000; [http://ssd.umich.edu/](http://ssd.umich.edu/)) typically recommends accommodations through a Verified Individualized Services and Accommodations (VISA) form. Any information you provide is private and confidential and will be treated as such.

## Mental Health and Well-Being

Students may experience stressors that can impact both their academic experience and their personal well-being. These may include academic pressures and challenges associated with relationships, mental health, alcohol or other drugs, identities, finances, etc. If you are experiencing concerns, seeking help is a courageous thing to do for yourself and those who care about you. If the source of your stressors is academic, please contact me so that we can find solutions together. For personal concerns, U-M offers a variety of resources, many which are listed on the [Resources for Student Well-being](https://wellbeing.studentlife.umich.edu/resources-list) webpage. You can also search for additional well-being resources [here](https://wellbeing.studentlife.umich.edu/well-being-resources). 

## Schedule

DLPy = _Deep Learning with Python (2nd edition)_ by Chollet    
DL = _Deep Learning_ by Goodfellow, Bengio and Courville    
D2L = _Dive into Deep Learning_ by Zhang, Lipton, Li and Smola    
UDL = _Understanding Deep Learning_ by Prince

_Note_: A "V" in the date column denotes a virtual lecture.

Date   | Topic | Reading Assignment 
---    | ---   | ---               
Jan 11 | Course logistics <br/> Introduction <br/> [slides](https://docs.google.com/presentation/d/1tK0h6NOYlwY_C6noNuVMLXSJFlYBy78z/edit?usp=sharing) | DLPy What is deep learning?, Chap. 1 <br/> DL Introduction, Chap. 1 <br/> D2L Introduction, Chap. 1
&nbsp; | **Linear Algebra Boot Camp** |
Jan 16 | Linear Algebra <br/> [notebook](https://colab.research.google.com/drive/1iUoVjOmG0P-ZZHBdevqb2AvKuXjdOSXD?usp=sharing) | D2L Geometry and Linear Algebraic Operations, Sec. 22.1.1-2
Jan 18 | Linear Algebra (continued) <br/> [notebook](https://colab.research.google.com/drive/1iUoVjOmG0P-ZZHBdevqb2AvKuXjdOSXD?usp=sharing) | D2L Geometry and Linear Algebraic Operations, Sec. 22.1.3-5 
Jan 23 <br/> V | Linear Algebra (continued) <br/> [notebook](https://colab.research.google.com/drive/1iUoVjOmG0P-ZZHBdevqb2AvKuXjdOSXD?usp=sharing) | D2L Geometry and Linear Algebraic Operations, Sec. 22.1.6-7 
&nbsp; | **Basics** |
Jan 25 <br/> V | Basic Elements of Linear Regression <br/> [slides](https://docs.google.com/presentation/d/12NsZ41XQW-bzVrHxAaEYEHAt9nz3gXoc/edit?usp=sharing&ouid=105036821118529706206&rtpof=true&sd=true) | D2L Linear Regression, Sec. 3.1.1
Jan 30 <br/> Feb 01 | Regression <br/> Loss functions and gradient descent <br/> [slides](https://docs.google.com/presentation/d/1TA58ZgXgz_1YWimJqY9QABhO6k92WHuO/edit?usp=sharing&ouid=105036821118529706206&rtpof=true&sd=true) | D2L Linear Regression, Sec. 3.1.1
Feb 06 | Regression wrap-up <br/> [slides](https://docs.google.com/presentation/d/1NVEbFvzqngbGY3jPeVd4rzF0kw4MiC7k/edit?usp=sharing&ouid=105036821118529706206&rtpof=true&sd=true) | D2L Linear Regression, Sec. 3.1.3-4 
Feb 08 | Classification <br/> Softmax Operation <br/> Cross Entropy Loss Function <br/> [slides](https://docs.google.com/presentation/d/1Oy5GxUB17gHjOv-gXqsnsClwbUWgkpOP/edit?usp=sharing&ouid=105036821118529706206&rtpof=true&sd=true) | D2L Softmax Regression, Sec. 4.1.1 <br/> D2L Loss Function, Sec. 4.1.2
Feb 13 | Softmax Derivatives <br/> Information Theory Basics <br/> [slides](https://docs.google.com/presentation/d/1eOlechaPRaSziUrYjQedpfTYvKzXgaqq/edit?usp=sharing&ouid=105036821118529706206&rtpof=true&sd=true) |  D2L Information Theory Basics, Sec. 4.1.3
&nbsp; | **TensorFlow/Keras** |
Feb 15 | TensorFlow, Keras, Google Colab <br/> [notebook](https://colab.research.google.com/drive/15vu6hlDdHFPWnagc6BZyS0PVSYoHqPaL?usp=sharing) | DLPy, Sec. 3.1-4 <br/> DLPy, Sec. 3.5.1-2
Feb 20 | First steps with TensorFlow <br/> [notebook](https://colab.research.google.com/drive/15vu6hlDdHFPWnagc6BZyS0PVSYoHqPaL?usp=sharing) | DLPy, Sec. 2.4.4 <br/> DLPy, Sec. 3.5.3-4
Feb 22 | STUDY DAY | 
Feb 27 | SPRING BREAK |
Feb 29 | SPRING BREAK |  
Mar 05 | MIDTERM EXAM |  
&nbsp; | **Fully Connected aka Dense Neural Networks** |
Mar 07 | Getting started with NNs: Classification MNIST <br/> [notebook](https://colab.research.google.com/drive/1JMsJMuENWLcz_ErLavJvfbca1ccGFOmL?usp=sharing) | DLPy, Sec. 2.1
Mar 12 | Getting started with NNs: Classification IMDB <br/> [notebook](https://colab.research.google.com/drive/1z-2T7UpS8bEe3jRUKkhs72rrf4JIwDr2?usp=sharing) <br/> Getting started with NNs: Regression Boston Housing Price <br/> [notebook](https://colab.research.google.com/drive/1lxAoBBfJcFFt4GAW56kIWqklXfesVXEd?usp=sharing) | DLPy, Sec. 4.1 <br/> DLPy, Sec. 4.3    
Mar 14 | Generalization <br/> Evaluating ML models <br/> [notebook](https://colab.research.google.com/drive/1WeWuusSyPo9-Mxf5Gi5VpDs5oKcunSxS?usp=sharing) | DLPy, Sec. 5.1-2    
Mar 19 | NO CLASS ([MIDAS Symposium](https://midas.umich.edu/ai-se-annual-symposium/)) |    
Mar 21 | Improving model fit <br/> Regularizing your model <br/> [notebook](https://colab.research.google.com/drive/1zgiSrmoTxT78-OJIXId8FqRS0IqRoGBa?usp=sharing) | DLPy, Sec. 5.3 <br/> DLPy, Sec. 5.4.4
&nbsp; | **Convolutional Neural Networks** |
Mar 26 | From Fully-Connected Layers to Convolutions <br/> [notebook]() | D2L, Sec. 7.1
Mar 28 | Convolutions for Images <br/> [notebook]() <br/> Padding and Stride <br/> [notebook]() <br/> Multiple Input and Multiple Output Channels <br/> [notebook]() | D2L, Sec. 7.2 <br/> D2L, Sec. 7.3-4
Apr 02 | Pooling <br/> [notebook]() <br/> LeNet <br/> Different ways to build Keras models <br/> [notebook]() | D2L, Sec. 7.5-6 <br/> DLPy, Sec. 7.2
&nbsp; | **Attention & Transformers / Machine Olfaction** |
Apr 04 | Guest Lecture by Michelle Krell Kydd, trained "nose" in flavors and fragrances <br/> [TEDx talk](https://youtu.be/PnWfdT0uBM4?si=ivxezKz4d_8RRoZR) <br/> [Blog](https://glasspetalsmoke.blogspot.com/) |  
Apr 09 | Introduction to the Attention Mechanism |  D2L, Sec. 11.1-3 <br/> UDL, Sec. 12.1-12.2
Apr 11 | Multi-Head Attention <br/> Self-Attention and Positional Encoding | D2L, Sec. 11.5-6 <br/> UDL, Sec. 12.3  
Apr 16 | Guest Lecture by UM alum Alex Wiltschko, Founder and CEO of [osmo.ai](https://www.osmo.ai/) |  
Apr 18 | The Transformer Architecture | D2L, Sec. 11.7 <br/> UDL, Sec. 12.4
Apr 23 | FINAL EXAM |  
